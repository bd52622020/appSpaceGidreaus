{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.0.18:4040\n",
       "SparkContext available as 'sc' (version = 3.0.0-preview2, master = local[*], app id = local-1592994205990)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark._\n",
       "import org.apache.spark.SparkContext._\n",
       "import org.apache.spark.sql._\n",
       "import org.apache.log4j._\n",
       "import scala.io.Source\n",
       "import java.nio.charset.CodingErrorAction\n",
       "import org.apache.spark.sql.functions._\n",
       "import java.io.File\n",
       "import java.nio.file.{Files, Paths}\n",
       "import scala.io.Codec\n",
       "import java.text.SimpleDateFormat\n",
       "import java.util.Date\n",
       "import scala.collection.mutable.ListBuffer\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.SparkContext._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.log4j._\n",
    "\n",
    "import scala.io.Source\n",
    "import java.nio.charset.CodingErrorAction\n",
    "import org.apache.spark.sql.functions._\n",
    "import java.io.File\n",
    "import java.nio.file.{Files, Paths}\n",
    "import scala.io.Codec\n",
    "import java.text.SimpleDateFormat\n",
    "import java.util.Date\n",
    "import scala.collection.mutable.ListBuffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RATINGS_PATH: String = /home/giedrius/Documents/appSpaceGidreaus/task6_movielens_pandas/ml-100k/u.data\n",
       "USERS_PATH: String = /home/giedrius/Documents/appSpaceGidreaus/task6_movielens_pandas/ml-100k/u.user\n",
       "MOVIES_PATH: String = /home/giedrius/Documents/appSpaceGidreaus/task6_movielens_pandas/ml-100k/u.item2\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//var CURR_PATH = Paths.get(System.getProperty(\"user.dir\"))\n",
    "//var DATA_PATH = Paths.get(CURR_PATH.getParent().toString, \"task6_movielens_pandas\",\"ml-100k\").toString()\n",
    "//var RATINGS_PATH = Paths.get(DATA_PATH, \"u.data\").toString()\n",
    "//var MOVIES_PATH = Paths.get(DATA_PATH, \"u.item2\").toString()\n",
    "//var USERS_PATH = Paths.get(DATA_PATH, \"u.user\").toString()\n",
    "var RATINGS_PATH = \"/home/giedrius/Documents/appSpaceGidreaus/task6_movielens_pandas/ml-100k/u.data\"\n",
    "var USERS_PATH = \"/home/giedrius/Documents/appSpaceGidreaus/task6_movielens_pandas/ml-100k/u.user\"\n",
    "var MOVIES_PATH = \"/home/giedrius/Documents/appSpaceGidreaus/task6_movielens_pandas/ml-100k/u.item2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratingsColumns: Array[String] = Array(user_id, item_id, rating, timestamp)\n",
       "userColumns: Array[String] = Array(user_id, age, gender, occupation, zip_code)\n",
       "moviesColumns: Array[String] = Array(movie_id, movie_title, release_date, video_release_date, IMDb_URL, unknown, Action, Adventure, Animation, Children's, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, Musical, Mystery, Romance, Sci-Fi, Thriller, War, Western)\n",
       "genres: Array[String] = Array(unknown, Action, Adventure, Animation, Children's, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, Musical, Mystery, Romance, Sci-Fi, Thriller, War, Western)\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var ratingsColumns = Array(\"user_id\", \"item_id\", \"rating\", \"timestamp\")\n",
    "var userColumns = Array(\"user_id\", \"age\",\"gender\", \"occupation\", \"zip_code\")\n",
    "var moviesColumns = Array(\"movie_id\", \"movie_title\", \"release_date\", \"video_release_date\", \"IMDb_URL\", \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\")\n",
    "var genres = moviesColumns.drop(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loadMovieNames: ()Map[Int,String]\n",
       "nameDict: org.apache.spark.broadcast.Broadcast[Map[Int,String]] = Broadcast(0)\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  def loadMovieNames() : Map[Int, String] = {\n",
    "    \n",
    "    // Handle character encoding issues:\n",
    "    implicit val codec = Codec(\"UTF-8\")\n",
    "    codec.onMalformedInput(CodingErrorAction.REPLACE)\n",
    "    codec.onUnmappableCharacter(CodingErrorAction.REPLACE)\n",
    "\n",
    "      \n",
    "    // Create a Map of Ints to Strings, and populate it from u.item.\n",
    "    var movieNames:Map[Int, String] = Map()\n",
    "    \n",
    "     val lines = Source.fromFile(MOVIES_PATH).getLines()\n",
    "     for (line <- lines) {\n",
    "       var fields = line.split('|')\n",
    "       if (fields.length > 1) {\n",
    "        movieNames += (fields(0).toInt -> fields(1))\n",
    "       }\n",
    "     }\n",
    "    \n",
    "     return movieNames\n",
    "  }\n",
    "var nameDict = sc.broadcast(loadMovieNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratingsDf: org.apache.spark.sql.DataFrame = [user_id: string, item_id: string ... 2 more fields]\n",
       "usersDf: org.apache.spark.sql.DataFrame = [user_id: string, age: string ... 3 more fields]\n",
       "moviesDf: org.apache.spark.sql.DataFrame = [movie_id: string, movie_title: string ... 22 more fields]\n",
       "mergedDf: org.apache.spark.sql.DataFrame = [user_id: string, item_id: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ratingsDf = spark.read.option(\"delimiter\", \"\\t\").csv(RATINGS_PATH).toDF(ratingsColumns:_*)\n",
    "val usersDf = spark.read.option(\"delimiter\", \"|\").csv(USERS_PATH).toDF(userColumns:_*)\n",
    "val moviesDf = spark.read.option(\"delimiter\", \"|\").csv(MOVIES_PATH).toDF(moviesColumns:_*)\n",
    "val mergedDf = ratingsDf.join(moviesDf, ratingsDf(\"item_id\") === moviesDf(\"movie_id\"), \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1) Q2) Print a list of the 10 movies that received the most number of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars (1977)               : 583\n",
      "Contact (1997)                 : 509\n",
      "Fargo (1996)                   : 508\n",
      "Return of the Jedi (1983)      : 507\n",
      "Liar Liar (1997)               : 485\n",
      "English Patient, The (1996)    : 481\n",
      "Scream (1996)                  : 478\n",
      "Toy Story (1995)               : 452\n",
      "Air Force One (1997)           : 431\n",
      "Independence Day (ID4) (1996)  : 429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "results_1: Array[(Int, Int)] = Array((583,50), (509,258), (508,100), (507,181), (485,294), (481,286), (478,288), (452,1), (431,300), (429,121))\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results_1 = ratingsDf.select(\"item_id\")\n",
    "                        .rdd\n",
    "                        .map(x => (x(0).toString().toInt,1))\n",
    "                        .reduceByKey( (x, y) => x + y )\n",
    "                        .map( x => (x._2, x._1) )\n",
    "                        .sortByKey(false)\n",
    "                        .take(10);\n",
    "\n",
    "results_1.foreach(x => println(\"%1$-30s : %2$-3s\".format(nameDict.value(x._2), x._1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3) Print a list of the number of ratings received by each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown     :    10\n",
      "Action      : 25589\n",
      "Adventure   : 13753\n",
      "Animation   :  3605\n",
      "Children's  :  7182\n",
      "Comedy      : 29832\n",
      "Crime       :  8055\n",
      "Documentary :   758\n",
      "Drama       : 39895\n",
      "Fantasy     :  1352\n",
      "Film-Noir   :  1733\n",
      "Horror      :  5317\n",
      "Musical     :  4954\n",
      "Mystery     :  5245\n",
      "Romance     : 19461\n",
      "Sci-Fi      : 12730\n",
      "Thriller    : 21872\n",
      "War         :  9398\n",
      "Western     :  1854\n"
     ]
    }
   ],
   "source": [
    "genres.foreach(x => println(\"%1$-11s : %2$5s\".format(x, mergedDf.groupBy(x)\n",
    "                                                     .count()\n",
    "                                                     .collect()\n",
    "                                                     .map(x => x(0).toString.toInt * x(1).toString.toInt)\n",
    "                                                     .max)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4) Print the oldest movie with a “5” rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DATE_FORMAT: String = dd-MMM-yyyy\n",
       "dateFormat: java.text.SimpleDateFormat = java.text.SimpleDateFormat@541ff80d\n",
       "parseDates: (x: org.apache.spark.sql.Row)Option[(java.util.Date, Int)]\n",
       "movieIDs: Array[Any] = Array(465, 1014, 222, 387, 95, 234, 603, 327, 201, 1137, 241, 4, 181, 196, 143, 423, 26, 427, 304, 229, 237, 480, 144, 518, 154, 1153, 382, 328, 132, 174, 96, 151, 195, 200, 195, 750, 23, 379, 427, 273, 98, 466, 673, 172, 174, 483, 202, 408, 228, 178, 10, 14, 69, 318, 339, 237, 218, 202, 89, 153, 595, 11, 520, 209, 222, 79, 237, 705, 64, 484, 508, 215, 705, 64, 304, 749, 321, 134, 256, 56, 271, 96, 197, 169, 558, 96, 522, 12, 20, 462, 781, 176, 197, 135, 173, 715, 163, 315, 60, 1, 288, 596, 144, 1060, 246, 419, 182, 50, 365, 742, 721, 611, 603, 382, 121, 81, 742, 1099, 1028, 961, 98, 2...\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var DATE_FORMAT = \"dd-MMM-yyyy\"\n",
    "val dateFormat = new SimpleDateFormat(DATE_FORMAT)\n",
    "\n",
    "def parseDates(x: Row) : Option[(Date, Int)] = {\n",
    "    try{\n",
    "        val date =  dateFormat.parse(x(1).toString) \n",
    "        Some((date, x(0).toString.toInt))\n",
    "    }\n",
    "    catch{\n",
    "        case e: Exception => None\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "val movieIDs = ratingsDf.select(\"item_id\", \"rating\")\n",
    "                        .filter(ratingsDf(\"rating\") === \"5\")\n",
    "                        .select(\"item_id\")\n",
    "                        .collect().map(x => x(0))\n",
    "\n",
    "val result_4 = moviesDf.select(\"movie_id\", \"release_date\")\n",
    "                             .filter(col(\"movie_id\").isin(movieIDs:_*))\n",
    "                             .rdd\n",
    "                             .flatMap(parseDates)\n",
    "                             .sortByKey()\n",
    "                             .take(1)\n",
    "                             .map(x => nameDict.value(x._2))\n",
    "\n",
    "println(result_4(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5) Print a list of the genre of the top 10 most rated movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getMovieGenres: (cols: org.apache.spark.sql.Row)(Int, String)\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getMovieGenres(cols: Row): (Int, String) = {\n",
    "    var columns = new ListBuffer[String]()\n",
    "    for (i <- 1 to cols.size-1){\n",
    "        if (cols(i) == \"1\"){\n",
    "            columns += genres(i-1)\n",
    "        }\n",
    "    }\n",
    "    val result = columns.toList.mkString(\", \")\n",
    "    return (cols(0).toString.toInt, result)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars (1977)               genres: Action, Adventure, Romance, Sci-Fi, War\n",
      "Contact (1997)                 genres: Drama, Sci-Fi\n",
      "Fargo (1996)                   genres: Crime, Drama, Thriller\n",
      "Return of the Jedi (1983)      genres: Action, Adventure, Romance, Sci-Fi, War\n",
      "Liar Liar (1997)               genres: Comedy\n",
      "English Patient, The (1996)    genres: Drama, Romance, War\n",
      "Scream (1996)                  genres: Horror, Thriller\n",
      "Toy Story (1995)               genres: Animation, Children's, Comedy\n",
      "Air Force One (1997)           genres: Action, Thriller\n",
      "Independence Day (ID4) (1996)  genres: Action, Sci-Fi, War\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "topRatedMoviesIds: Array[String] = Array(50, 258, 100, 181, 294, 286, 288, 1, 300, 121)\n",
       "result_5: scala.collection.immutable.Map[Int,String] = Map(288 -> Horror, Thriller, 121 -> Action, Sci-Fi, War, 1 -> Animation, Children's, Comedy, 286 -> Drama, Romance, War, 181 -> Action, Adventure, Romance, Sci-Fi, War, 50 -> Action, Adventure, Romance, Sci-Fi, War, 258 -> Drama, Sci-Fi, 300 -> Action, Thriller, 294 -> Comedy, 100 -> Crime, Drama, Thriller)\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val topRatedMoviesIds = results_1.map(x => x._2.toString)\n",
    "val result_5 = moviesDf.select(\"movie_id\",  genres: _*)\n",
    "                               .filter(col(\"movie_id\").isin(topRatedMoviesIds:_*))\n",
    "                               .rdd\n",
    "                               .map(getMovieGenres)\n",
    "                               .collect()\n",
    "                               .toMap\n",
    "                                \n",
    "results_1.foreach(x => println(\"%1$-30s genres: %2$-3s\".format(nameDict.value(x._2), result_5.get(x._2).get)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6) Print the title of the movie that was rated the most by students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "studendsID: Array[Any] = Array(9, 30, 32, 33, 36, 37, 49, 52, 66, 67, 68, 73, 76, 81, 94, 99, 101, 103, 104, 110, 117, 124, 135, 139, 140, 153, 154, 159, 188, 193, 198, 203, 206, 221, 223, 226, 228, 230, 241, 245, 246, 248, 249, 257, 258, 259, 262, 270, 274, 276, 281, 286, 291, 301, 303, 304, 307, 314, 320, 322, 323, 324, 327, 332, 341, 347, 348, 350, 355, 359, 361, 363, 366, 367, 368, 369, 372, 377, 378, 391, 393, 397, 408, 416, 425, 428, 429, 434, 442, 451, 453, 459, 461, 462, 466, 471, 472, 473, 476, 477, 482, 484, 496, 497, 501, 502, 511, 517, 521, 528, 532, 534, 541, 542, 550, 560, 565, 566, 577, 580, 582, 584, 586, 588, 592, 599, 609, 610, 618, 619, 621, 624, 631, 632, 640, 641, 642, 646, 649, 654, 660, 674, 679, 684, 700, 705, 706, 710, 711, 712, 725, 727, 729, 742, 757, 758, 759...\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val studendsID = usersDf.select(\"user_id\", \"occupation\")\n",
    "                        .filter(col(\"occupation\") === \"student\")\n",
    "                        .select(\"user_id\")\n",
    "                        .collect()\n",
    "                        .map(x => x(0))\n",
    "\n",
    "val result_6 = ratingsDf.select(\"user_id\", \"item_id\")\n",
    "                         .filter(col(\"user_id\").isin(studendsID:_*))\n",
    "                         .rdd\n",
    "                         .map(x => (x(1), 1))\n",
    "                         .reduceByKey( (x, y) => x+y)\n",
    "                         .map(x => (x._2, x._1))\n",
    "                         .sortByKey(false)\n",
    "                         .take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scream (1996)\n"
     ]
    }
   ],
   "source": [
    "println(nameDict.value(result_6(0)._2.toString.toInt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7) Print the list of movies that received the highest number of “5” rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars (1977)                  : 325\n",
      "Fargo (1996)                      : 227\n",
      "Godfather, The (1972)             : 214\n",
      "Raiders of the Lost Ark (1981)    : 202\n",
      "Pulp Fiction (1994)               : 188\n",
      "Schindler's List (1993)           : 186\n",
      "Silence of the Lambs, The (1991)  : 181\n",
      "Titanic (1997)                    : 179\n",
      "Empire Strikes Back, The (1980)   : 172\n",
      "Return of the Jedi (1983)         : 171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "results_7: Array[(Int, Any)] = Array((325,50), (227,100), (214,127), (202,174), (188,56), (186,318), (181,98), (179,313), (172,172), (171,181))\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results_7 = mergedDf.select(\"item_id\",\"rating\")\n",
    "                          .filter(col(\"rating\") === \"5\")\n",
    "                          .rdd\n",
    "                          .map(x => (x(0), 1))\n",
    "                          .reduceByKey( (x, y) => x+y)\n",
    "                          .map(x => (x._2, x._1))\n",
    "                          .sortByKey(false)\n",
    "                          .take(10)\n",
    "\n",
    "results_7.foreach(x => println(\"%1$-33s : %2$-3s\".format(nameDict.value(x._2.toString.toInt), x._1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8) Print the list of zip codes corresponding to the highest number of users that rated movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zipcode 55414: 9 \n",
      "zipcode 55105: 6 \n",
      "zipcode 10003: 5 \n",
      "zipcode 55337: 5 \n",
      "zipcode 20009: 5 \n",
      "zipcode 55454: 4 \n",
      "zipcode 55408: 4 \n",
      "zipcode 27514: 4 \n",
      "zipcode 61801: 3 \n",
      "zipcode 94043: 3 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "userIDs: Array[Any] = Array(196, 186, 22, 244, 166, 298, 115, 253, 305, 6, 62, 286, 200, 210, 224, 303, 122, 194, 291, 234, 119, 167, 299, 308, 95, 38, 102, 63, 160, 50, 301, 225, 290, 97, 157, 181, 278, 276, 7, 10, 284, 201, 287, 246, 242, 249, 99, 178, 251, 81, 260, 25, 59, 72, 87, 42, 292, 20, 13, 138, 60, 57, 223, 189, 243, 92, 241, 254, 293, 127, 222, 267, 11, 8, 162, 279, 145, 28, 135, 32, 90, 216, 250, 271, 265, 198, 168, 110, 58, 237, 94, 128, 44, 264, 41, 82, 262, 174, 43, 84, 269, 259, 85, 213, 121, 49, 155, 68, 172, 19, 268, 5, 80, 66, 18, 26, 130, 256, 1, 56, 15, 207, 232, 52, 161, 148, 125, 83, 272, 151, 54, 16, 91, 294, 229, 36, 70, 14, 295, 233, 214, 192, 100, 307, 297, 193, 113, 275, 219, 218, 123, 158, 302, 23, 296, 33, 154, 77, 270, 187, 170, 101, 184, 112, 133, 215, 6...\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val userIDs = ratingsDf.select(\"user_id\")\n",
    "                       .distinct\n",
    "                       .collect()\n",
    "                       .map(x => x(0))\n",
    "\n",
    "val results_8 = usersDf.select(\"zip_code\", \"user_id\")\n",
    "                       .filter(col(\"user_id\").isin(userIDs:_*))\n",
    "                       .groupBy(\"zip_code\")\n",
    "                       .count()\n",
    "                       .orderBy($\"count\".desc)\n",
    "                       .take(10)\n",
    "\n",
    "results_8.foreach(x => println(\"zipcode %1$5s: %2$-2s\".format(x(0), x(1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9) Find the most rated movie by users in the age group 20 to 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scream (1996)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user_25_30_IDs: Array[Any] = Array(1, 3, 4, 16, 22, 24, 31, 33, 35, 37, 49, 50, 54, 56, 66, 69, 73, 75, 76, 81, 96, 99, 105, 117, 118, 128, 130, 132, 135, 139, 150, 153, 154, 156, 159, 162, 165, 177, 180, 198, 203, 216, 217, 228, 240, 245, 248, 249, 255, 259, 267, 268, 274, 276, 282, 285, 287, 293, 301, 304, 305, 307, 314, 317, 322, 323, 324, 327, 332, 336, 342, 348, 353, 355, 359, 361, 363, 366, 369, 372, 373, 377, 391, 394, 399, 405, 408, 412, 414, 416, 431, 432, 435, 439, 442, 445, 448, 449, 456, 459, 466, 470, 472, 477, 487, 493, 496, 497, 501, 502, 509, 511, 517, 519, 532, 534, 542, 551, 561, 566, 567, 584, 586, 589, 595, 596, 597, 599, 603, 608, 610, 622, 626, 627, 635, 640, 641, 649, 665, 671, 677, 679, 682, 689, 697, 705, 706, 709, 711, 712, 715, 717, 721, 725, 726, 727, 734, 74...\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val user_25_30_IDs = usersDf.select(\"user_id\", \"age\")\n",
    "                        .rdd\n",
    "                        .map(x => (x(0), x(1).toString.toInt))\n",
    "                        .filter(x => x._2 > 19 && x._2 < 26 )\n",
    "                        .map(x => x._1)\n",
    "                        .collect()\n",
    "\n",
    "val result_9 = ratingsDf.select(\"user_id\", \"item_id\")\n",
    "                         .filter(col(\"user_id\").isin(user_25_30_IDs:_*))\n",
    "                         .select(\"item_id\")\n",
    "                         .groupBy(\"item_id\")\n",
    "                         .count()\n",
    "                         .orderBy($\"count\".desc)\n",
    "                         .take(1)\n",
    "                         .map(x => nameDict.value(x(0).toString.toInt))\n",
    "\n",
    "println(result_9(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q10) Print the list of movies that were rate after year 1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 movies:\n",
      "Anne Frank Remembered (1995)\n",
      "Harlem (1993)\n",
      "Audrey Rose (1977)\n",
      "Now and Then (1995)\n",
      "Red Rock West (1992)\n",
      "Two if by Sea (1996)\n",
      "U.S. Marshalls (1998)\n",
      "August (1996)\n",
      "Homeward Bound: The Incredible Journey (1993)\n",
      "Back to the Future (1985)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "result_10: Array[String] = Array(Anne Frank Remembered (1995), Harlem (1993), Audrey Rose (1977), Now and Then (1995), Red Rock West (1992), Two if by Sea (1996), U.S. Marshalls (1998), August (1996), Homeward Bound: The Incredible Journey (1993), Back to the Future (1985))\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val result_10 = ratingsDf.select(\"item_id\", \"timestamp\")\n",
    "                          .rdd\n",
    "                          .map(x => (x(0).toString.toInt , new Date(x(1).toString.toLong *1000L)))\n",
    "                          .filter(x => x._2.compareTo(dateFormat.parse(\"31-Dec-1959\")) > 0)\n",
    "                          .map(x => x._1)\n",
    "                          .distinct\n",
    "                          .take(10)\n",
    "                          .map(x => nameDict.value(x))\n",
    "                          \n",
    "println(\"First 10 movies:\")                        \n",
    "result_10.foreach(println)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
